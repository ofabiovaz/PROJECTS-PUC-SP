{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fabio Vaz Lab11_raw.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnUpls-zct9b"
      },
      "source": [
        "Fabio Gustavo Gomes Vaz <br> RA: 00282997"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERABT_PiG9y0"
      },
      "source": [
        "Pontif√≠cia Universidade Cat√≥lica de S√£o Paulo \n",
        "\n",
        "`Ci√™ncia de Dados e Intelig√™ncia Artificial`\n",
        "\n",
        "#üéì Aula 11 - Introdu√ß√£o √†s Redes Neurais Artificiais\n",
        "28 de outubro de 2021\n",
        "\n",
        "\n",
        "---\n",
        "> üë®‚Äçüè´*Professor Rooney Coelho (rracoelho@pucsp.br)*\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0xaiXDvf7hS"
      },
      "source": [
        "## Introdu√ß√£o\n",
        "\n",
        "Redes Neurais s√£o uma estrutura de aprendizado de m√°quina que tenta imitar o padr√£o de aprendizado de redes neurais biol√≥gicas naturais. As redes neurais biol√≥gicas t√™m neur√¥nios interconectados com dendritos que recebem entradas e, com base nessas entradas, produzem um sinal de sa√≠da por meio de um ax√¥nio para outro neur√¥nio. Tentaremos imitar esse processo por meio do uso de Redes Neurais Artificiais (RNA), que iremos chamar apenas de redes neurais a partir de agora. O processo de cria√ß√£o de uma rede neural come√ßa com a forma mais b√°sica, um √∫nico perceptron.\n",
        "\n",
        "## O Perceptron\n",
        " \n",
        "Vamos come√ßar nossa discuss√£o falando sobre o Perceptron! Um perceptron tem uma ou mais entradas, uma polariza√ß√£o, uma fun√ß√£o de ativa√ß√£o e uma √∫nica sa√≠da. O perceptron recebe entradas, multiplica-as por algum peso e ent√£o as passa para uma fun√ß√£o de ativa√ß√£o para produzir uma sa√≠da. Existem muitas fun√ß√µes de ativa√ß√£o poss√≠veis para escolher, como a fun√ß√£o log√≠stica, uma fun√ß√£o trigonom√©trica, uma fun√ß√£o de degrau, etc. Tamb√©m nos certificamos de adicionar um vi√©s ao perceptron, isso evita problemas onde todas as entradas podem ser iguais a zero (o que significa nenhum peso multiplicativo teria efeito). Confira o diagrama abaixo para uma visualiza√ß√£o de um perceptron:\n",
        "\n",
        "![title](https://www.kdnuggets.com/wp-content/uploads/perceptron.jpg)\n",
        "\n",
        "\n",
        "Assim que tivermos a sa√≠da, podemos compar√°-la com um r√≥tulo conhecido e ajustar os pesos de acordo (os pesos geralmente come√ßam com valores de inicializa√ß√£o aleat√≥rios). Continuamos repetindo esse processo at√© atingir um n√∫mero m√°ximo de itera√ß√µes permitidas ou uma taxa de erro aceit√°vel.\n",
        "\n",
        "Para criar uma rede neural, simplesmente come√ßamos a adicionar camadas de perceptrons, criando um modelo perceptron de v√°rias camadas de uma rede neural. Voc√™ ter√° uma camada de entrada que recebe diretamente suas entradas de recursos e uma camada de sa√≠da que criar√° as sa√≠das resultantes. Quaisquer camadas intermedi√°rias s√£o conhecidas como camadas ocultas porque n√£o \"v√™em\" diretamente as entradas ou sa√≠das de recursos. Para uma visualiza√ß√£o disso confira o diagrama abaixo.\n",
        "\n",
        "![title](https://www.kdnuggets.com/wp-content/uploads/ann-in-hidden-out.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9n7tqOD0Mqy"
      },
      "source": [
        "### 1) Entendendo os dados\n",
        "\n",
        "Usaremos o conjunto de dados de c√¢ncer de mama do SciKit Learn, que possui v√°rias caracter√≠sticas de tumores com uma classe rotulada indicando se o tumor era maligno ou benigno. Tentaremos criar um modelo de rede neural que possa incorporar essas caracter√≠sticas e tentar prever r√≥tulos malignos ou benignos para tumores que nunca vimos antes. Vamos come√ßar obtendo os dados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9GhPUlvY0gN"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqXKlySHZVln"
      },
      "source": [
        "Imprima os dados `cancer`. Note que n√£o se trata de um DataFrame e sim de um dicion√°rio. O use do `Pandas` n√£o √© uma imposi√ß√£o do SciKit Learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzkdymaUZ0T6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3bc76a-4106-442b-a773-de39c348a74d"
      },
      "source": [
        "# Execute este bloco para ver as chaves do dicion√°rio\n",
        "cancer.keys()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdCenpa9aN5o"
      },
      "source": [
        "Imprima a chave `DESCR` para uma descri√ß√£o completa dos dados. A fun√ß√£o `print` aplicada nessa inst√¢ncia ir√° mostrar um texto descritivo da fonte dos dados e do que eles significam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-fTMUvGaCB6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df1911ef-53bd-41c3-80b3-b2cb6ffcd36a"
      },
      "source": [
        "print(cancer.DESCR)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry \n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
            "        13 is Radius SE, field 23 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgBlKKe-auIN"
      },
      "source": [
        "Use o par√¢metro `shape` (exemplo X.shape) para os dados (chave `data` do dicion√°rio) e veja quantas linhas e colunas temos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZBLg4axapFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf3bd85e-d89c-4b98-91d5-f0dac089d621"
      },
      "source": [
        "cancer.data.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg-V1rCYIjDR"
      },
      "source": [
        "### 2) Determina√ß√£o das features e do target\n",
        "\n",
        "Atribua as features (chave `data`) na vari√°vel `X` e o target (chave `target`) na vari√°vel `y`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt52rJy07L_3"
      },
      "source": [
        "X = cancer.data\n",
        "y = cancer.target"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLJ1blFrI27K"
      },
      "source": [
        "### 3) Divis√£o dos dados entre treinamento e teste\n",
        "\n",
        "Da mesma forma que se fez nos laborat√≥rios anteriores, divida as `features` e o `target` com a fun√ß√£o `train_test_split` do SciKit Learn. Use a propor√ß√£o padr√£o para essa separa√ß√£o."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v357zYr28_kX"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train , X_test, y_train, y_test = train_test_split(X,y)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0vLRrqMJEPx"
      },
      "source": [
        "### 4) Pr√©-processamento dos dados\n",
        "\n",
        "A rede neural pode ter dificuldade em convergir antes do n√∫mero m√°ximo de itera√ß√µes permitidas se os dados n√£o estiverem normalizados. O Perceptron multicamadas √© sens√≠vel ao dimensionamento de recursos, portanto, √© altamente recomend√°vel dimensionar seus dados. Observe que voc√™ deve aplicar a mesma escala ao conjunto de testes para obter resultados significativos. Existem muitos m√©todos diferentes para normaliza√ß√£o de dados, usaremos o StandardScaler do SciKit Learn para padroniza√ß√£o. Utilize os par√¢metros adicionais da fun√ß√£o como padr√£o."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3tv6YCoDiHX"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Use aqui a fun√ß√£o StandardScaler para a normaliza√ß√£o, busque em exemplos como se utiliza essa fun√ß√£o\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkuHHZ3SJURb"
      },
      "source": [
        "### 5) Treinamento do modelo\n",
        "\n",
        "Nesta etapa treinaremos o nosso modelo. Tal como os demais modelos do SciKit Learn, a modelagem usando redes neurais √© bem similar. Utilizaremos aqui o Perceptron de m√∫ltiplas camadas como classificador (Multi-Layer Perceptron) da biblioteca neural_network do SciKit-Learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3qP8HT5FQz9"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjIKV_2Ae53L"
      },
      "source": [
        "Agora criaremos uma inst√¢ncia do modelo. H√° v√°rios par√¢metros que podemos escolher para definir e personalizar, por√©m definiremos apenas os tamanhos das camadas ocultas `hidden_layer_sizes`. Para esse par√¢metro, voc√™ passa uma tupla que consiste no n√∫mero de neur√¥nios que deseja em cada camada, onde a en√©sima entrada na tupla representa o n√∫mero de neur√¥nios na en√©sima camada do modelo MLP. \n",
        "\n",
        "```\n",
        "mlp = MLPClassifier(hidden_layer_sizes= TUPLA_VEM_AQUI)\n",
        "```\n",
        "\n",
        "Existem muitas maneiras de escolher esses n√∫meros, mas para simplificar, escolheremos 3 camadas com o mesmo n√∫mero de neur√¥nios (30). Usamos esse valor como uma heur√≠stca, onde esse n√∫mero √© igual a quantidade de feautres do modelo!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqtQRFENf0tz"
      },
      "source": [
        "# Digite seu c√≥digo aqui\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoaPcI0rgECo"
      },
      "source": [
        "Agora que o modelo foi feito, podemos realizar o treinamento do nosso modelo com os dados reservados para treinamento, lembre-se de que esses dados j√° foram processados e escalonados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVKtlzIdgRt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b03baffc-6937-4327-e0c8-f0839e6f52d0"
      },
      "source": [
        "# Digite seu c√≥digo aqui\n",
        "mlp.fit(X_train,y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHpzrPIXgaZN"
      },
      "source": [
        "Podemos ver a sa√≠da que mostra os valores padr√£o dos outros par√¢metros do modelo. Tente alterar esses valores e veja a influ√™ncia deles na precis√£o do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDUtWf2QJheP"
      },
      "source": [
        "### 6) Previs√µes e avalia√ß√£o\n",
        "\n",
        "Agora que temos um modelo, podemos us√°-lo para obter previs√µes. Fa√ßa isso com o m√©todo `predict()` com os dados reservados para teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clEX4OzuJf_t"
      },
      "source": [
        "y_pred = mlp.predict(X_test)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiGkfUrjhTyZ"
      },
      "source": [
        "Agora que se fez a avalia√ß√£o dos dados reservados para teste, use a fun√ß√£o`confusion_matrix` para ver onde a classifica√ß√£o teve precis√£o.\n",
        "\n",
        "Imprima o resultado da fun√ß√£o `classification_report`, que √© aplicada no target reservado teste e nos valores que foram previstos pelo modelo. Aqui voc√™ tem um resultado mais detalhado da previs√£o do seu modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf2wZ9P3hTDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d7c31e-d304-4460-9c5c-5f835dbeb2dc"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "# Escreva seu c√≥digo aqui\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[45,  0],\n",
              "       [ 5, 93]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYvdHLV9cOTZ",
        "outputId": "2d5ef2a2-c21c-4edc-d374-5fa64e35c884"
      },
      "source": [
        "target_names = ['class 0', 'class 1']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.90      1.00      0.95        45\n",
            "     class 1       1.00      0.95      0.97        98\n",
            "\n",
            "    accuracy                           0.97       143\n",
            "   macro avg       0.95      0.97      0.96       143\n",
            "weighted avg       0.97      0.97      0.97       143\n",
            "\n"
          ]
        }
      ]
    }
  ]
}